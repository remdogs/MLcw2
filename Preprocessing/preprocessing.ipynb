{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP3009 Cw2 – Data Pre-processing\n",
    "\n",
    "\n",
    "\n",
    "- TrainDataset_before_process.csv (400 patients)\n",
    "\n",
    "\n",
    "In this notebook we:\n",
    "1. Load the training dataset and inspect its dimensions and basic structure.\n",
    "2. Handle missing data (values encoded as 999).\n",
    "3. Separate:\n",
    "   - patient ID\n",
    "   - targets (PCR, RFS)\n",
    "   - feature matrix\n",
    "4. Identify numerical vs categorical features.\n",
    "5. Build a pre-processing transformer:\n",
    "   - numeric: median imputation + standardisation\n",
    "   - categorical: most frequent imputation + one-hot encoding\n",
    "6. Apply the pre-processing to obtain clean feature matrices ready for modelling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset/dataset.csv already exists — skipping conversion.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "input_file = \"Dataset/TrainDataset2025-2.xls\"\n",
    "output_file = \"Dataset/dataset.csv\"\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    print(f\"Converting {input_file} → {output_file} ...\")\n",
    "    df_raw = pd.read_excel(input_file)\n",
    "    df_raw.to_csv(output_file, index=False)\n",
    "    print(\"Conversion complete.\")\n",
    "else:\n",
    "    print(f\"{output_file} already exists — skipping conversion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Load the training dataset and inspect dimensions\n",
    "\n",
    "We now:\n",
    "- load TrainDataset_before_process.csv into a pandas DataFrame,\n",
    "- check the shape(number of rows and columns),\n",
    "- look at the first few rows to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape (rows, columns): (400, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pCR (outcome)</th>\n",
       "      <th>RelapseFreeSurvival (outcome)</th>\n",
       "      <th>Age</th>\n",
       "      <th>ER</th>\n",
       "      <th>PgR</th>\n",
       "      <th>HER2</th>\n",
       "      <th>TrippleNegative</th>\n",
       "      <th>ChemoGrade</th>\n",
       "      <th>Proliferation</th>\n",
       "      <th>...</th>\n",
       "      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_ZoneEntropy</th>\n",
       "      <th>original_glszm_ZonePercentage</th>\n",
       "      <th>original_glszm_ZoneVariance</th>\n",
       "      <th>original_ngtdm_Busyness</th>\n",
       "      <th>original_ngtdm_Coarseness</th>\n",
       "      <th>original_ngtdm_Complexity</th>\n",
       "      <th>original_ngtdm_Contrast</th>\n",
       "      <th>original_ngtdm_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRG002174</td>\n",
       "      <td>1</td>\n",
       "      <td>144.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517172</td>\n",
       "      <td>0.375126</td>\n",
       "      <td>3.325332</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>3880771.500</td>\n",
       "      <td>473.464852</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.182615</td>\n",
       "      <td>0.030508</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRG002178</td>\n",
       "      <td>0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>0.444391</td>\n",
       "      <td>3.032144</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>2372009.744</td>\n",
       "      <td>59.459710</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.003685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRG002204</td>\n",
       "      <td>1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>0.534549</td>\n",
       "      <td>2.485848</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>1540027.421</td>\n",
       "      <td>33.935384</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.006447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRG002206</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>2.606255</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>6936740.794</td>\n",
       "      <td>46.859265</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.004543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRG002210</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>0.462282</td>\n",
       "      <td>2.809279</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>1265399.054</td>\n",
       "      <td>39.621023</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  pCR (outcome)  RelapseFreeSurvival (outcome)   Age  ER  PgR  \\\n",
       "0  TRG002174              1                          144.0  41.0   0    0   \n",
       "1  TRG002178              0                          142.0  39.0   1    1   \n",
       "2  TRG002204              1                          135.0  31.0   0    0   \n",
       "3  TRG002206              0                           12.0  35.0   0    0   \n",
       "4  TRG002210              0                          109.0  61.0   1    0   \n",
       "\n",
       "   HER2  TrippleNegative  ChemoGrade  Proliferation  ...  \\\n",
       "0     0                1           3              3  ...   \n",
       "1     0                0           3              3  ...   \n",
       "2     0                1           2              1  ...   \n",
       "3     0                1           3              3  ...   \n",
       "4     0                0           2              1  ...   \n",
       "\n",
       "   original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                       0.517172   \n",
       "1                                       0.444391   \n",
       "2                                       0.534549   \n",
       "3                                       0.506185   \n",
       "4                                       0.462282   \n",
       "\n",
       "   original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n",
       "0                                      0.375126                    3.325332   \n",
       "1                                      0.444391                    3.032144   \n",
       "2                                      0.534549                    2.485848   \n",
       "3                                      0.506185                    2.606255   \n",
       "4                                      0.462282                    2.809279   \n",
       "\n",
       "   original_glszm_ZonePercentage  original_glszm_ZoneVariance  \\\n",
       "0                       0.002314                  3880771.500   \n",
       "1                       0.005612                  2372009.744   \n",
       "2                       0.006752                  1540027.421   \n",
       "3                       0.003755                  6936740.794   \n",
       "4                       0.006521                  1265399.054   \n",
       "\n",
       "   original_ngtdm_Busyness  original_ngtdm_Coarseness  \\\n",
       "0               473.464852                   0.000768   \n",
       "1                59.459710                   0.004383   \n",
       "2                33.935384                   0.007584   \n",
       "3                46.859265                   0.005424   \n",
       "4                39.621023                   0.006585   \n",
       "\n",
       "   original_ngtdm_Complexity  original_ngtdm_Contrast  original_ngtdm_Strength  \n",
       "0                   0.182615                 0.030508                 0.000758  \n",
       "1                   0.032012                 0.001006                 0.003685  \n",
       "2                   0.024062                 0.000529                 0.006447  \n",
       "3                   0.013707                 0.000178                 0.004543  \n",
       "4                   0.034148                 0.001083                 0.005626  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"/Users/remylieberman/Desktop/code/MLcw2/Dataset/dataset.csv\"  \n",
    "\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "print(\"Training dataset shape (rows, columns):\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next inspect:\n",
    "- the column names,\n",
    "- the data types,\n",
    "\n",
    "to get an idea of which columns are clinical, which are MRI features,\n",
    "and which might be targets (PCR, RFS) or IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['ID', 'pCR (outcome)', 'RelapseFreeSurvival (outcome)', 'Age', 'ER', 'PgR', 'HER2', 'TrippleNegative', 'ChemoGrade', 'Proliferation', 'HistologyType', 'LNStatus', 'TumourStage', 'Gene', 'original_shape_Elongation', 'original_shape_Flatness', 'original_shape_LeastAxisLength', 'original_shape_MajorAxisLength', 'original_shape_Maximum2DDiameterColumn', 'original_shape_Maximum2DDiameterRow', 'original_shape_Maximum2DDiameterSlice', 'original_shape_Maximum3DDiameter', 'original_shape_MeshVolume', 'original_shape_MinorAxisLength', 'original_shape_Sphericity', 'original_shape_SurfaceArea', 'original_shape_SurfaceVolumeRatio', 'original_shape_VoxelVolume', 'original_firstorder_10Percentile', 'original_firstorder_90Percentile', 'original_firstorder_Energy', 'original_firstorder_Entropy', 'original_firstorder_InterquartileRange', 'original_firstorder_Kurtosis', 'original_firstorder_Maximum', 'original_firstorder_MeanAbsoluteDeviation', 'original_firstorder_Mean', 'original_firstorder_Median', 'original_firstorder_Minimum', 'original_firstorder_Range', 'original_firstorder_RobustMeanAbsoluteDeviation', 'original_firstorder_RootMeanSquared', 'original_firstorder_Skewness', 'original_firstorder_TotalEnergy', 'original_firstorder_Uniformity', 'original_firstorder_Variance', 'original_glcm_Autocorrelation', 'original_glcm_ClusterProminence', 'original_glcm_ClusterShade', 'original_glcm_ClusterTendency', 'original_glcm_Contrast', 'original_glcm_Correlation', 'original_glcm_DifferenceAverage', 'original_glcm_DifferenceEntropy', 'original_glcm_DifferenceVariance', 'original_glcm_Id', 'original_glcm_Idm', 'original_glcm_Idmn', 'original_glcm_Idn', 'original_glcm_Imc1', 'original_glcm_Imc2', 'original_glcm_InverseVariance', 'original_glcm_JointAverage', 'original_glcm_JointEnergy', 'original_glcm_JointEntropy', 'original_glcm_MCC', 'original_glcm_MaximumProbability', 'original_glcm_SumAverage', 'original_glcm_SumEntropy', 'original_glcm_SumSquares', 'original_gldm_DependenceEntropy', 'original_gldm_DependenceNonUniformity', 'original_gldm_DependenceNonUniformityNormalized', 'original_gldm_DependenceVariance', 'original_gldm_GrayLevelNonUniformity', 'original_gldm_GrayLevelVariance', 'original_gldm_HighGrayLevelEmphasis', 'original_gldm_LargeDependenceEmphasis', 'original_gldm_LargeDependenceHighGrayLevelEmphasis', 'original_gldm_LargeDependenceLowGrayLevelEmphasis', 'original_gldm_LowGrayLevelEmphasis', 'original_gldm_SmallDependenceEmphasis', 'original_gldm_SmallDependenceHighGrayLevelEmphasis', 'original_gldm_SmallDependenceLowGrayLevelEmphasis', 'original_glrlm_GrayLevelNonUniformity', 'original_glrlm_GrayLevelNonUniformityNormalized', 'original_glrlm_GrayLevelVariance', 'original_glrlm_HighGrayLevelRunEmphasis', 'original_glrlm_LongRunEmphasis', 'original_glrlm_LongRunHighGrayLevelEmphasis', 'original_glrlm_LongRunLowGrayLevelEmphasis', 'original_glrlm_LowGrayLevelRunEmphasis', 'original_glrlm_RunEntropy', 'original_glrlm_RunLengthNonUniformity', 'original_glrlm_RunLengthNonUniformityNormalized', 'original_glrlm_RunPercentage', 'original_glrlm_RunVariance', 'original_glrlm_ShortRunEmphasis', 'original_glrlm_ShortRunHighGrayLevelEmphasis', 'original_glrlm_ShortRunLowGrayLevelEmphasis', 'original_glszm_GrayLevelNonUniformity', 'original_glszm_GrayLevelNonUniformityNormalized', 'original_glszm_GrayLevelVariance', 'original_glszm_HighGrayLevelZoneEmphasis', 'original_glszm_LargeAreaEmphasis', 'original_glszm_LargeAreaHighGrayLevelEmphasis', 'original_glszm_LargeAreaLowGrayLevelEmphasis', 'original_glszm_LowGrayLevelZoneEmphasis', 'original_glszm_SizeZoneNonUniformity', 'original_glszm_SizeZoneNonUniformityNormalized', 'original_glszm_SmallAreaEmphasis', 'original_glszm_SmallAreaHighGrayLevelEmphasis', 'original_glszm_SmallAreaLowGrayLevelEmphasis', 'original_glszm_ZoneEntropy', 'original_glszm_ZonePercentage', 'original_glszm_ZoneVariance', 'original_ngtdm_Busyness', 'original_ngtdm_Coarseness', 'original_ngtdm_Complexity', 'original_ngtdm_Contrast', 'original_ngtdm_Strength']\n",
      "\n",
      "Data types:\n",
      "ID                                object\n",
      "pCR (outcome)                      int64\n",
      "RelapseFreeSurvival (outcome)    float64\n",
      "Age                              float64\n",
      "ER                                 int64\n",
      "                                  ...   \n",
      "original_ngtdm_Busyness          float64\n",
      "original_ngtdm_Coarseness        float64\n",
      "original_ngtdm_Complexity        float64\n",
      "original_ngtdm_Contrast          float64\n",
      "original_ngtdm_Strength          float64\n",
      "Length: 121, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Column names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identify ID and target columns\n",
    "\n",
    "From the coursework description, the dataset should contain:\n",
    "- A patient ID column\n",
    "- A PCR column (classification target),\n",
    "- An RFS column (regression target),\n",
    "- 11 clinical features,\n",
    "- 107 MRI features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COL = \"ID\"\n",
    "PCR_COL = \"pCR (outcome)\"\n",
    "RFS_COL = \"RelapseFreeSurvival (outcome)\"\n",
    "\n",
    "for col in [ID_COL, PCR_COL, RFS_COL]:\n",
    "    if col not in df.columns:\n",
    "        print(f\"WARNING: column '{col}' not found in DataFrame columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handle missing data (999 → NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total '999' entries before replacement: 0\n",
      "Total NaN entries after replacement: 105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gene                                                  88\n",
       "pCR (outcome)                                          5\n",
       "ChemoGrade                                             3\n",
       "HistologyType                                          3\n",
       "Proliferation                                          2\n",
       "LNStatus                                               1\n",
       "PgR                                                    1\n",
       "HER2                                                   1\n",
       "TrippleNegative                                        1\n",
       "original_glrlm_GrayLevelVariance                       0\n",
       "original_gldm_SmallDependenceEmphasis                  0\n",
       "original_gldm_SmallDependenceHighGrayLevelEmphasis     0\n",
       "original_gldm_SmallDependenceLowGrayLevelEmphasis      0\n",
       "original_glrlm_GrayLevelNonUniformity                  0\n",
       "original_glrlm_GrayLevelNonUniformityNormalized        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many 999 values exist before replacement\n",
    "num_999_before = (df == 999).sum().sum()\n",
    "print(\"Total '999' entries before replacement:\", num_999_before)\n",
    "\n",
    "# Replace 999 with NaN\n",
    "df = df.replace(999, np.nan)\n",
    "\n",
    "# Check how many NaNs we have now\n",
    "num_nan_after = df.isna().sum().sum()\n",
    "print(\"Total NaN entries after replacement:\", num_nan_after)\n",
    "\n",
    "# Optional: show columns with most missing values\n",
    "missing_per_col = df.isna().sum().sort_values(ascending=False)\n",
    "missing_per_col.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split into ID, targets, and feature matrix\n",
    "\n",
    "We now separate:\n",
    "- patient_id: ID column (not used as a feature),\n",
    "- y_pcr: PCR label (classification target),\n",
    "- y_rfs: RFS value (regression target),\n",
    "- X_full: all feature columns used as input to the models (clinical + MRI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (400, 118)\n",
      "PCR target shape: (400,)\n",
      "RFS target shape: (400,)\n"
     ]
    }
   ],
   "source": [
    "patient_id = df[ID_COL]\n",
    "y_pcr = df[PCR_COL]\n",
    "y_rfs = df[RFS_COL]\n",
    "\n",
    "X_full = df.drop(columns=[ID_COL, PCR_COL, RFS_COL])\n",
    "\n",
    "print(\"Feature matrix shape:\", X_full.shape)\n",
    "print(\"PCR target shape:\", y_pcr.shape)\n",
    "print(\"RFS target shape:\", y_rfs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Identify clinical vs MRI features\n",
    "\n",
    "From the assignment brief, there are:\n",
    "- **11 clinical features**:\n",
    "  - Age, ER, PgR, HER2, TripleNegative status, Chemotherapy Grade,\n",
    "    Tumour Proliferation, Histology Type, Lymph node Status,\n",
    "    Tumour Stage, Gene\n",
    "- **107 MRI-based features** extracted from Pyradiomics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clinical features (expected up to 11): 11\n",
      "Number of MRI features (expected around 107): 107\n"
     ]
    }
   ],
   "source": [
    "clinical_features = [\n",
    "    \"Age\",\n",
    "    \"ER\",\n",
    "    \"PgR\",                \n",
    "    \"HER2\",\n",
    "    \"TrippleNegative\",\n",
    "    \"ChemoGrade\",\n",
    "    \"Proliferation\",\n",
    "    \"HistologyType\",\n",
    "    \"LNStatus\",\n",
    "    \"TumourStage\",\n",
    "    \"Gene\",\n",
    "]\n",
    "\n",
    "missing_clinical = [c for c in clinical_features if c not in X_full.columns]\n",
    "if missing_clinical:\n",
    "    print(\"WARNING: The following clinical feature names not found in X_full:\")\n",
    "    print(missing_clinical)\n",
    "\n",
    "mri_features = [c for c in X_full.columns if c not in clinical_features]\n",
    "\n",
    "print(f\"Number of clinical features (expected up to 11): {len(clinical_features) - len(missing_clinical)}\")\n",
    "print(f\"Number of MRI features (expected around 107): {len(mri_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identify numerical and categorical input features\n",
    "\n",
    "For pre-processing we further classify features into:\n",
    "- **Numeric** (int/float): suitable for median imputation and standardisation.\n",
    "- **Categorical** (e.g. strings, codes): suitable for most-frequent imputation and one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numeric features: 118\n",
      "Number of categorical features: 0\n",
      "\n",
      "Example numeric features: ['Age', 'ER', 'PgR', 'HER2', 'TrippleNegative', 'ChemoGrade', 'Proliferation', 'HistologyType', 'LNStatus', 'TumourStage']\n",
      "Example categorical features: []\n"
     ]
    }
   ],
   "source": [
    "numeric_features = X_full.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X_full.select_dtypes(exclude=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "print(\"Number of numeric features:\", len(numeric_features))\n",
    "print(\"Number of categorical features:\", len(categorical_features))\n",
    "print(\"\\nExample numeric features:\", numeric_features[:10])\n",
    "print(\"Example categorical features:\", categorical_features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build a pre-processing transformer\n",
    "\n",
    "We now create a **ColumnTransformer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;Age&#x27;, &#x27;ER&#x27;, &#x27;PgR&#x27;, &#x27;HER2&#x27;, &#x27;TrippleNegative&#x27;,\n",
       "                                  &#x27;ChemoGrade&#x27;, &#x27;Proliferation&#x27;,\n",
       "                                  &#x27;HistologyType&#x27;, &#x27;LNStatus&#x27;, &#x27;TumourStage&#x27;,\n",
       "                                  &#x27;Gene&#x27;, &#x27;original_shape_Elongation&#x27;,\n",
       "                                  &#x27;original_shape_Flatness&#x27;,\n",
       "                                  &#x27;original_shape_LeastAxisLength&#x27;,\n",
       "                                  &#x27;original_sha...\n",
       "                                  &#x27;original_shape_SurfaceVolumeRatio&#x27;,\n",
       "                                  &#x27;original_shape_VoxelVolume&#x27;,\n",
       "                                  &#x27;original_firstorder_10Percentile&#x27;,\n",
       "                                  &#x27;original_firstorder_90Percentile&#x27;,\n",
       "                                  &#x27;original_firstorder_Energy&#x27;,\n",
       "                                  &#x27;original_firstorder_Entropy&#x27;,\n",
       "                                  &#x27;original_firstorder_InterquartileRange&#x27;, ...]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;Age&#x27;, &#x27;ER&#x27;, &#x27;PgR&#x27;, &#x27;HER2&#x27;, &#x27;TrippleNegative&#x27;,\n",
       "                                  &#x27;ChemoGrade&#x27;, &#x27;Proliferation&#x27;,\n",
       "                                  &#x27;HistologyType&#x27;, &#x27;LNStatus&#x27;, &#x27;TumourStage&#x27;,\n",
       "                                  &#x27;Gene&#x27;, &#x27;original_shape_Elongation&#x27;,\n",
       "                                  &#x27;original_shape_Flatness&#x27;,\n",
       "                                  &#x27;original_shape_LeastAxisLength&#x27;,\n",
       "                                  &#x27;original_sha...\n",
       "                                  &#x27;original_shape_SurfaceVolumeRatio&#x27;,\n",
       "                                  &#x27;original_shape_VoxelVolume&#x27;,\n",
       "                                  &#x27;original_firstorder_10Percentile&#x27;,\n",
       "                                  &#x27;original_firstorder_90Percentile&#x27;,\n",
       "                                  &#x27;original_firstorder_Energy&#x27;,\n",
       "                                  &#x27;original_firstorder_Entropy&#x27;,\n",
       "                                  &#x27;original_firstorder_InterquartileRange&#x27;, ...]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;, &#x27;ER&#x27;, &#x27;PgR&#x27;, &#x27;HER2&#x27;, &#x27;TrippleNegative&#x27;, &#x27;ChemoGrade&#x27;, &#x27;Proliferation&#x27;, &#x27;HistologyType&#x27;, &#x27;LNStatus&#x27;, &#x27;TumourStage&#x27;, &#x27;Gene&#x27;, &#x27;original_shape_Elongation&#x27;, &#x27;original_shape_Flatness&#x27;, &#x27;original_shape_LeastAxisLength&#x27;, &#x27;original_shape_MajorAxisLength&#x27;, &#x27;original_shape_Maximum2DDiameterColumn&#x27;, &#x27;original_shape_Maximum2DDiameterRow&#x27;, &#x27;original_shape_Maximum2DDiameterSlice&#x27;, &#x27;original_shape_Maximum3DDiameter&#x27;, &#x27;original_shape_MeshVolume&#x27;, &#x27;original_shape_MinorAxisLength&#x27;, &#x27;original_shape_Sphericity&#x27;, &#x27;original_shape_SurfaceArea&#x27;, &#x27;original_shape_SurfaceVolumeRatio&#x27;, &#x27;original_shape_VoxelVolume&#x27;, &#x27;original_firstorder_10Percentile&#x27;, &#x27;original_firstorder_90Percentile&#x27;, &#x27;original_firstorder_Energy&#x27;, &#x27;original_firstorder_Entropy&#x27;, &#x27;original_firstorder_InterquartileRange&#x27;, &#x27;original_firstorder_Kurtosis&#x27;, &#x27;original_firstorder_Maximum&#x27;, &#x27;original_firstorder_MeanAbsoluteDeviation&#x27;, &#x27;original_firstorder_Mean&#x27;, &#x27;original_firstorder_Median&#x27;, &#x27;original_firstorder_Minimum&#x27;, &#x27;original_firstorder_Range&#x27;, &#x27;original_firstorder_RobustMeanAbsoluteDeviation&#x27;, &#x27;original_firstorder_RootMeanSquared&#x27;, &#x27;original_firstorder_Skewness&#x27;, &#x27;original_firstorder_TotalEnergy&#x27;, &#x27;original_firstorder_Uniformity&#x27;, &#x27;original_firstorder_Variance&#x27;, &#x27;original_glcm_Autocorrelation&#x27;, &#x27;original_glcm_ClusterProminence&#x27;, &#x27;original_glcm_ClusterShade&#x27;, &#x27;original_glcm_ClusterTendency&#x27;, &#x27;original_glcm_Contrast&#x27;, &#x27;original_glcm_Correlation&#x27;, &#x27;original_glcm_DifferenceAverage&#x27;, &#x27;original_glcm_DifferenceEntropy&#x27;, &#x27;original_glcm_DifferenceVariance&#x27;, &#x27;original_glcm_Id&#x27;, &#x27;original_glcm_Idm&#x27;, &#x27;original_glcm_Idmn&#x27;, &#x27;original_glcm_Idn&#x27;, &#x27;original_glcm_Imc1&#x27;, &#x27;original_glcm_Imc2&#x27;, &#x27;original_glcm_InverseVariance&#x27;, &#x27;original_glcm_JointAverage&#x27;, &#x27;original_glcm_JointEnergy&#x27;, &#x27;original_glcm_JointEntropy&#x27;, &#x27;original_glcm_MCC&#x27;, &#x27;original_glcm_MaximumProbability&#x27;, &#x27;original_glcm_SumAverage&#x27;, &#x27;original_glcm_SumEntropy&#x27;, &#x27;original_glcm_SumSquares&#x27;, &#x27;original_gldm_DependenceEntropy&#x27;, &#x27;original_gldm_DependenceNonUniformity&#x27;, &#x27;original_gldm_DependenceNonUniformityNormalized&#x27;, &#x27;original_gldm_DependenceVariance&#x27;, &#x27;original_gldm_GrayLevelNonUniformity&#x27;, &#x27;original_gldm_GrayLevelVariance&#x27;, &#x27;original_gldm_HighGrayLevelEmphasis&#x27;, &#x27;original_gldm_LargeDependenceEmphasis&#x27;, &#x27;original_gldm_LargeDependenceHighGrayLevelEmphasis&#x27;, &#x27;original_gldm_LargeDependenceLowGrayLevelEmphasis&#x27;, &#x27;original_gldm_LowGrayLevelEmphasis&#x27;, &#x27;original_gldm_SmallDependenceEmphasis&#x27;, &#x27;original_gldm_SmallDependenceHighGrayLevelEmphasis&#x27;, &#x27;original_gldm_SmallDependenceLowGrayLevelEmphasis&#x27;, &#x27;original_glrlm_GrayLevelNonUniformity&#x27;, &#x27;original_glrlm_GrayLevelNonUniformityNormalized&#x27;, &#x27;original_glrlm_GrayLevelVariance&#x27;, &#x27;original_glrlm_HighGrayLevelRunEmphasis&#x27;, &#x27;original_glrlm_LongRunEmphasis&#x27;, &#x27;original_glrlm_LongRunHighGrayLevelEmphasis&#x27;, &#x27;original_glrlm_LongRunLowGrayLevelEmphasis&#x27;, &#x27;original_glrlm_LowGrayLevelRunEmphasis&#x27;, &#x27;original_glrlm_RunEntropy&#x27;, &#x27;original_glrlm_RunLengthNonUniformity&#x27;, &#x27;original_glrlm_RunLengthNonUniformityNormalized&#x27;, &#x27;original_glrlm_RunPercentage&#x27;, &#x27;original_glrlm_RunVariance&#x27;, &#x27;original_glrlm_ShortRunEmphasis&#x27;, &#x27;original_glrlm_ShortRunHighGrayLevelEmphasis&#x27;, &#x27;original_glrlm_ShortRunLowGrayLevelEmphasis&#x27;, &#x27;original_glszm_GrayLevelNonUniformity&#x27;, &#x27;original_glszm_GrayLevelNonUniformityNormalized&#x27;, &#x27;original_glszm_GrayLevelVariance&#x27;, &#x27;original_glszm_HighGrayLevelZoneEmphasis&#x27;, &#x27;original_glszm_LargeAreaEmphasis&#x27;, &#x27;original_glszm_LargeAreaHighGrayLevelEmphasis&#x27;, &#x27;original_glszm_LargeAreaLowGrayLevelEmphasis&#x27;, &#x27;original_glszm_LowGrayLevelZoneEmphasis&#x27;, &#x27;original_glszm_SizeZoneNonUniformity&#x27;, &#x27;original_glszm_SizeZoneNonUniformityNormalized&#x27;, &#x27;original_glszm_SmallAreaEmphasis&#x27;, &#x27;original_glszm_SmallAreaHighGrayLevelEmphasis&#x27;, &#x27;original_glszm_SmallAreaLowGrayLevelEmphasis&#x27;, &#x27;original_glszm_ZoneEntropy&#x27;, &#x27;original_glszm_ZonePercentage&#x27;, &#x27;original_glszm_ZoneVariance&#x27;, &#x27;original_ngtdm_Busyness&#x27;, &#x27;original_ngtdm_Coarseness&#x27;, &#x27;original_ngtdm_Complexity&#x27;, &#x27;original_ngtdm_Contrast&#x27;, &#x27;original_ngtdm_Strength&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['Age', 'ER', 'PgR', 'HER2', 'TrippleNegative',\n",
       "                                  'ChemoGrade', 'Proliferation',\n",
       "                                  'HistologyType', 'LNStatus', 'TumourStage',\n",
       "                                  'Gene', 'original_shape_Elongation',\n",
       "                                  'original_shape_Flatness',\n",
       "                                  'original_shape_LeastAxisLength',\n",
       "                                  'original_sha...\n",
       "                                  'original_shape_SurfaceVolumeRatio',\n",
       "                                  'original_shape_VoxelVolume',\n",
       "                                  'original_firstorder_10Percentile',\n",
       "                                  'original_firstorder_90Percentile',\n",
       "                                  'original_firstorder_Energy',\n",
       "                                  'original_firstorder_Entropy',\n",
       "                                  'original_firstorder_InterquartileRange', ...]),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 [])])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fit the pre-processor and transform the features\n",
    "\n",
    "We now fit the pre-processing pipeline on the full training feature matrix X_full\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the pre-processing pipeline on the full training feature matrix x_full\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature matrix type: <class 'numpy.ndarray'>\n",
      "Processed feature matrix shape: (400, 118)\n"
     ]
    }
   ],
   "source": [
    "X_processed = preprocessor.fit_transform(X_full)\n",
    "\n",
    "print(\"Processed feature matrix type:\", type(X_processed))\n",
    "print(\"Processed feature matrix shape:\", X_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: 118\n",
      "Categorical features: 0\n",
      "Remaining NaNs in features: 0\n",
      "Preprocessed dataset saved to:\n",
      "Dataset/preprocessed_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/swvbhb6s2nv6gz94ctr_j93c0000gn/T/ipykernel_23621/656098034.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_clean[\"ID\"] = patient_id.values\n",
      "/var/folders/2c/swvbhb6s2nv6gz94ctr_j93c0000gn/T/ipykernel_23621/656098034.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_clean[\"pCR (outcome)\"] = y_pcr.values\n",
      "/var/folders/2c/swvbhb6s2nv6gz94ctr_j93c0000gn/T/ipykernel_23621/656098034.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_clean[\"RelapseFreeSurvival (outcome)\"] = y_rfs.values\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in [ID_COL, PCR_COL, RFS_COL]]\n",
    "\n",
    "X_full = df[feature_cols].copy()\n",
    "\n",
    "\n",
    "all_nan_cols = X_full.columns[X_full.isna().all()]\n",
    "if len(all_nan_cols) > 0:\n",
    "    print(\"Dropping completely empty feature columns:\", list(all_nan_cols))\n",
    "    X_full = X_full.drop(columns=all_nan_cols)\n",
    "    feature_cols = X_full.columns.tolist()  # update feature list\n",
    "\n",
    "numeric_features = X_full.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X_full.select_dtypes(exclude=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "print(\"Numeric features:\", len(numeric_features))\n",
    "print(\"Categorical features:\", len(categorical_features))\n",
    "\n",
    "\n",
    "df_clean = X_full.copy()\n",
    "\n",
    "if numeric_features:\n",
    "    num_imputer = SimpleImputer(strategy=\"median\")\n",
    "    df_clean[numeric_features] = num_imputer.fit_transform(df_clean[numeric_features])\n",
    "\n",
    "if categorical_features:\n",
    "    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    df_clean[categorical_features] = cat_imputer.fit_transform(df_clean[categorical_features])\n",
    "\n",
    "print(\"Remaining NaNs in features:\", df_clean.isna().sum().sum())\n",
    "\n",
    "\n",
    "df_clean[\"ID\"] = patient_id.values\n",
    "df_clean[\"pCR (outcome)\"] = y_pcr.values\n",
    "df_clean[\"RelapseFreeSurvival (outcome)\"] = y_rfs.values\n",
    "\n",
    "cols_in_order = [c for c in df.columns if c in df_clean.columns]\n",
    "df_clean = df_clean[cols_in_order]\n",
    "\n",
    "\n",
    "output_path = \"Dataset/preprocessed_dataset.csv\"\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Preprocessed dataset saved to:\\n{output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns that will be dropped because they contain missing values:\n",
      "[]\n",
      "\n",
      "New shape after removing incomplete feature columns: (400, 121)\n",
      "\n",
      "Cleaned dataset saved to:\n",
      "Dataset/preprocessed_dataset_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_full = pd.read_csv(\"Dataset/preprocessed_dataset.csv\")\n",
    "\n",
    "protected_cols = [\"ID\", \"pCR (outcome)\", \"RelapseFreeSurvival (outcome)\"]\n",
    "\n",
    "cols_with_missing = df_full.columns[df_full.isna().any()].tolist()\n",
    "\n",
    "cols_to_drop = [col for col in cols_with_missing if col not in protected_cols]\n",
    "\n",
    "print(\"Columns that will be dropped because they contain missing values:\")\n",
    "print(cols_to_drop)\n",
    "\n",
    "df_cleaned = df_full.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"\\nNew shape after removing incomplete feature columns:\", df_cleaned.shape)\n",
    "\n",
    "output_path = \"Dataset/preprocessed_dataset_cleaned.csv\"\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nCleaned dataset saved to:\\n{output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded for validation.\n",
      "Shape: (400, 121)\n",
      "\n",
      "Total NaN values in dataset: 5\n",
      "\n",
      "Columns with missing (NaN) values:\n",
      "['pCR (outcome)']\n",
      "\n",
      "NaN count per column:\n",
      "pCR (outcome)    5\n",
      "dtype: int64\n",
      "\n",
      "Total blank-string ('') entries: 0\n",
      "\n",
      "Columns containing blank values (empty strings):\n",
      "[]\n",
      "\n",
      "Blank count per column:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Columns that are completely empty (all NaN or all blank):\n",
      "[]\n",
      "\n",
      "Number of rows with missing values: 5\n",
      "\n",
      "Validation complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "check_df = pd.read_csv(\"Dataset/preprocessed_dataset.csv\")\n",
    "\n",
    "print(\"Dataset loaded for validation.\")\n",
    "print(\"Shape:\", check_df.shape)\n",
    "\n",
    "total_nans = check_df.isna().sum().sum()\n",
    "print(f\"\\nTotal NaN values in dataset: {total_nans}\")\n",
    "\n",
    "cols_with_nan = check_df.columns[check_df.isna().any()].tolist()\n",
    "print(\"\\nColumns with missing (NaN) values:\")\n",
    "print(cols_with_nan)\n",
    "\n",
    "print(\"\\nNaN count per column:\")\n",
    "print(check_df.isna().sum()[check_df.isna().sum() > 0])\n",
    "\n",
    "blank_mask = (check_df.applymap(lambda x: isinstance(x, str) and x.strip() == \"\"))\n",
    "total_blanks = blank_mask.sum().sum()\n",
    "print(f\"\\nTotal blank-string ('') entries: {total_blanks}\")\n",
    "\n",
    "cols_with_blank = blank_mask.columns[blank_mask.any()].tolist()\n",
    "print(\"\\nColumns containing blank values (empty strings):\")\n",
    "print(cols_with_blank)\n",
    "\n",
    "print(\"\\nBlank count per column:\")\n",
    "print(blank_mask.sum()[blank_mask.sum() > 0])\n",
    "\n",
    "\n",
    "empty_cols = check_df.columns[(check_df.isna().all()) | (blank_mask.all())].tolist()\n",
    "print(\"\\nColumns that are completely empty (all NaN or all blank):\")\n",
    "print(empty_cols)\n",
    "\n",
    "rows_with_missing = check_df[check_df.isna().any(axis=1)]\n",
    "print(f\"\\nNumber of rows with missing values: {rows_with_missing.shape[0]}\")\n",
    "\n",
    "print(\"\\nValidation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Summary\n",
    "\n",
    "The validation checks confirm that all clinical and MRI features have been fully cleaned and imputed, with no remaining NaN or blank values. No columns are completely empty. The only missing values in the dataset are 5 entries in the PCR outcome column, which indicates that these patients simply have no recorded PCR label. These rows will be removed only for the PCR classification task. All other data is complete and ready for feature selection and modelling.\n",
    "\n",
    "we have also created a new dataset csv with the updated data, that can be used in diferent sections\n",
    "all datarows with missing data that mostfrqeuent and mediun couldnt support, were removed.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
